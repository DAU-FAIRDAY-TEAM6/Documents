## 피드백 내용 정리
- Light GCN 같이 아직 사용하지 않은 기술 스택 같은 건 발표자료에서 제외.
  - 추후에 모델이 변경될 수 있음
<br>

- BERT 모델이 무겁고 복잡하기 때문에 다른 방법도 찾아보는게 어떻겠는가?
  - BERT 모델은 feature가 너무 많아 무겁다.
  - sequence to vector 나 word to vector 같은 가벼운 방법으로 변경해도 괜찮을 것 같다.
  - 개인적인 학사 형의 의견으론 가벼운 모델을 찾는 걸 추천

    
<br>

- poi 추천과 추천 모델의 기술들을 나열하다 갑자기 서버 아키텍처가 나와 혼란스러운 느낌이 있다.
<br>

- 학습 데이터를 어떻게 전처리 했는지 설명이 있으면 좋을 것 같다.
<br>

- BERT 텍스트 임베딩 & 데이터의 크기와 개수 등에 대한 설명을 발표 자료에 포함하면 좋을 것 같다.
<br>

- 비교 모델인 BPR이 옛날 기술이긴 하지만 생각보다 성능이 좋아서 뛰어넘기 어려울 수도 있다.
<br>

- 발표 자료에서 페르소나 부분의 예제의 변경이 필요해보인다.
<br>

- 개인 마다 다른 즉, 개인화된 이 더 강조됐으면 좋겠다.
<br><br><br><br>

## 발표 자료에서 수정해야 할 부분
- 발표 자료 기준 첫번째 페르소나 부분 보강
- 두번째 페르소나 부분에서 기존 모델의 문제점을 확실히 보여줄 수 있는 다른 예제로 변경 (분위기 관련 예시로 변경)
- 개인화를 더욱 강조
- 데이터 전처리, 버트 임베딩에 대한 가시적인 설명 필요 (서버 아키텍처 나오기 전)
- 사용 기술 페이지에서 아직 쓰지 않은 기술들은 제거하고 맨 뒤 부록 페이지로 이동 (제외)
- 페이지마다 현재 목차 추가
